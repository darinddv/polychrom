{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "polychrom_contact_map_tutorial"
   },
   "source": [
    "# Polychrom Tutorial: Contact Map Analysis\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/darinddv/polychrom/blob/master/tutorials/03_contact_map_analysis.ipynb)\n",
    "\n",
    "Welcome to the contact map analysis tutorial! This tutorial focuses on analyzing polymer simulation data and creating Hi-C-like contact maps from polychrom simulations.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Load and analyze polychrom simulation trajectories\n",
    "- Generate contact maps from 3D coordinates\n",
    "- Calculate polymer physics observables\n",
    "- Compare with experimental Hi-C data\n",
    "- Advanced contact map analysis techniques\n",
    "\n",
    "**Prerequisites:**\n",
    "- Complete the [Basic Polymer Simulation Tutorial](https://colab.research.google.com/github/darinddv/polychrom/blob/master/tutorials/01_basic_polymer_simulation.ipynb)\n",
    "- Understanding of Hi-C experimental technique (helpful)\n",
    "\n",
    "**Contact Maps in Chromatin Biology:**\n",
    "Contact maps visualize the spatial organization of chromatin by showing which genomic regions are in close physical proximity. They're the primary output of Hi-C experiments and crucial for understanding 3D genome organization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "installation"
   },
   "source": [
    "## 1. Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# Install conda and OpenMM (required for polychrom)\n",
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()\n",
    "\n",
    "# Install OpenMM via conda\n",
    "!conda install -c omnia openmm -y\n",
    "\n",
    "# Install polychrom dependencies\n",
    "!pip install numpy scipy h5py pandas joblib matplotlib seaborn cooltools\n",
    "\n",
    "# Clone and install polychrom\n",
    "!git clone https://github.com/darinddv/polychrom.git\n",
    "!cd polychrom && pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart_runtime"
   },
   "source": [
    "**⚠️ Important:** After running the installation cell above, **restart the runtime** and continue below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_libraries"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from scipy import ndimage\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Add polychrom to path\n",
    "sys.path.append('/content/polychrom')\n",
    "\n",
    "# Import polychrom modules\n",
    "import polychrom\n",
    "from polychrom import forcekits, forces, simulation, starting_conformations\n",
    "from polychrom.hdf5_format import HDF5Reporter\n",
    "import polychrom.polymer_analyses\n",
    "import polychrom.contactmaps\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "generate_data"
   },
   "source": [
    "## 2. Generate Sample Data\n",
    "\n",
    "First, let's run a quick simulation to generate trajectory data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_simulation"
   },
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "N = 1000  # Number of monomers\n",
    "num_blocks = 20\n",
    "steps_per_block = 1000\n",
    "\n",
    "print(f\"Running simulation: {N} monomers, {num_blocks} blocks\")\n",
    "\n",
    "# Create initial conformation\n",
    "polymer = starting_conformations.grow_cubic(N, boxSize=15)\n",
    "\n",
    "# Setup simulation\n",
    "output_dir = \"contact_analysis_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "reporter = HDF5Reporter(folder=output_dir, max_data_length=50, overwrite=True)\n",
    "\n",
    "sim = simulation.Simulation(\n",
    "    platform=\"CPU\",\n",
    "    integrator=\"variableLangevin\",\n",
    "    temperature=300,\n",
    "    collision_rate=0.01,\n",
    "    N=N,\n",
    "    reporters=[reporter]\n",
    ")\n",
    "\n",
    "# Set initial data and add forces\n",
    "sim.set_data(polymer, center=True)\n",
    "sim.add_force(forcekits.polymer_chains(sim))\n",
    "sim.add_force(forces.spherical_confinement(sim, density=0.3, k=5.0))\n",
    "sim.add_force(forces.polynomial_repulsive(sim, trunc=1.5, radiusMult=1.05))\n",
    "\n",
    "# Energy minimization\n",
    "sim.local_energy_minimization()\n",
    "print(\"Energy minimization completed\")\n",
    "\n",
    "# Run simulation\n",
    "trajectory = []\n",
    "for i in range(num_blocks):\n",
    "    sim.do_block(steps_per_block)\n",
    "    current_coords = sim.get_data().copy()\n",
    "    trajectory.append(current_coords)\n",
    "    \n",
    "    if (i + 1) % 5 == 0:\n",
    "        eK, eP = sim.get_energy()\n",
    "        print(f\"Block {i+1}/{num_blocks}: Ek={eK:.1f}, Ep={eP:.1f}\")\n",
    "\n",
    "reporter.dump_data()\n",
    "trajectory = np.array(trajectory)\n",
    "\n",
    "print(f\"Simulation completed!\")\n",
    "print(f\"Trajectory shape: {trajectory.shape} (blocks, monomers, 3D coordinates)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "contact_map_basics"
   },
   "source": [
    "## 3. Contact Map Fundamentals\n",
    "\n",
    "Let's understand what contact maps are and how to calculate them from 3D coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "basic_contact_map"
   },
   "outputs": [],
   "source": [
    "def calculate_distance_map(coords):\n",
    "    \"\"\"Calculate distance matrix between all pairs of monomers\"\"\"\n",
    "    n = len(coords)\n",
    "    distance_map = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            dist = np.linalg.norm(coords[i] - coords[j])\n",
    "            distance_map[i, j] = dist\n",
    "            distance_map[j, i] = dist\n",
    "    \n",
    "    return distance_map\n",
    "\n",
    "def distance_to_contact_map(distance_map, cutoff=2.0):\n",
    "    \"\"\"Convert distance map to binary contact map\"\"\"\n",
    "    return (distance_map < cutoff).astype(int)\n",
    "\n",
    "def contact_probability_map(distance_map, cutoff=2.0):\n",
    "    \"\"\"Convert distance to contact probability using exponential decay\"\"\"\n",
    "    return np.exp(-distance_map / cutoff)\n",
    "\n",
    "# Use the last frame for analysis\n",
    "final_coords = trajectory[-1]\n",
    "\n",
    "# Calculate different representations\n",
    "distance_map = calculate_distance_map(final_coords)\n",
    "contact_map_binary = distance_to_contact_map(distance_map, cutoff=2.0)\n",
    "contact_map_prob = contact_probability_map(distance_map, cutoff=2.0)\n",
    "\n",
    "# Visualize different representations\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Distance map\n",
    "im1 = axes[0].imshow(distance_map, cmap='viridis_r', origin='lower')\n",
    "axes[0].set_title('Distance Map')\n",
    "axes[0].set_xlabel('Monomer index')\n",
    "axes[0].set_ylabel('Monomer index')\n",
    "plt.colorbar(im1, ax=axes[0], label='Distance (units)')\n",
    "\n",
    "# Binary contact map\n",
    "im2 = axes[1].imshow(contact_map_binary, cmap='Reds', origin='lower')\n",
    "axes[1].set_title('Binary Contact Map (cutoff=2.0)')\n",
    "axes[1].set_xlabel('Monomer index')\n",
    "axes[1].set_ylabel('Monomer index')\n",
    "plt.colorbar(im2, ax=axes[1], label='Contact (0/1)')\n",
    "\n",
    "# Probability contact map\n",
    "im3 = axes[2].imshow(contact_map_prob, cmap='Reds', origin='lower')\n",
    "axes[2].set_title('Probability Contact Map')\n",
    "axes[2].set_xlabel('Monomer index')\n",
    "axes[2].set_ylabel('Monomer index')\n",
    "plt.colorbar(im3, ax=axes[2], label='Contact probability')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Contact map statistics:\")\n",
    "print(f\"Total contacts (cutoff=2.0): {np.sum(contact_map_binary) // 2}\")\n",
    "print(f\"Contact density: {np.sum(contact_map_binary) / (N * N):.4f}\")\n",
    "print(f\"Average distance: {np.mean(distance_map):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trajectory_analysis"
   },
   "source": [
    "## 4. Trajectory-Averaged Contact Maps\n",
    "\n",
    "Real contact maps should be averaged over many conformations to get ensemble averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ensemble_contact_map"
   },
   "outputs": [],
   "source": [
    "def calculate_ensemble_contact_map(trajectory, cutoff=2.0, start_frame=10):\n",
    "    \"\"\"Calculate contact map averaged over trajectory\"\"\"\n",
    "    n_frames, n_monomers, _ = trajectory.shape\n",
    "    ensemble_map = np.zeros((n_monomers, n_monomers))\n",
    "    \n",
    "    # Skip initial frames for equilibration\n",
    "    for frame in range(start_frame, n_frames):\n",
    "        coords = trajectory[frame]\n",
    "        distance_map = calculate_distance_map(coords)\n",
    "        contact_map = distance_to_contact_map(distance_map, cutoff)\n",
    "        ensemble_map += contact_map\n",
    "    \n",
    "    # Normalize by number of frames\n",
    "    ensemble_map = ensemble_map / (n_frames - start_frame)\n",
    "    return ensemble_map\n",
    "\n",
    "# Calculate ensemble contact map\n",
    "ensemble_contacts = calculate_ensemble_contact_map(trajectory, cutoff=2.0, start_frame=10)\n",
    "\n",
    "# Compare single frame vs ensemble\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Single frame\n",
    "im1 = axes[0].imshow(contact_map_binary, cmap='Reds', origin='lower', vmin=0, vmax=1)\n",
    "axes[0].set_title('Single Frame Contact Map')\n",
    "axes[0].set_xlabel('Monomer index')\n",
    "axes[0].set_ylabel('Monomer index')\n",
    "plt.colorbar(im1, ax=axes[0], label='Contact')\n",
    "\n",
    "# Ensemble averaged\n",
    "im2 = axes[1].imshow(ensemble_contacts, cmap='Reds', origin='lower', vmin=0, vmax=1)\n",
    "axes[1].set_title('Ensemble Averaged Contact Map')\n",
    "axes[1].set_xlabel('Monomer index')\n",
    "axes[1].set_ylabel('Monomer index')\n",
    "plt.colorbar(im2, ax=axes[1], label='Contact probability')\n",
    "\n",
    "# Log scale (Hi-C style)\n",
    "log_contacts = np.log10(ensemble_contacts + 1e-6)\n",
    "im3 = axes[2].imshow(log_contacts, cmap='Reds', origin='lower')\n",
    "axes[2].set_title('Log-scale Contact Map')\n",
    "axes[2].set_xlabel('Monomer index')\n",
    "axes[2].set_ylabel('Monomer index')\n",
    "plt.colorbar(im3, ax=axes[2], label='log10(contact probability)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Ensemble contact statistics:\")\n",
    "print(f\"Maximum contact probability: {np.max(ensemble_contacts):.3f}\")\n",
    "print(f\"Mean contact probability: {np.mean(ensemble_contacts):.6f}\")\n",
    "print(f\"Contact probability at distance 10: {ensemble_contacts[500, 510]:.4f}\")\n",
    "print(f\"Contact probability at distance 100: {ensemble_contacts[500, 600]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "polymer_scaling"
   },
   "source": [
    "## 5. Polymer Scaling Analysis\n",
    "\n",
    "Contact probability in polymers follows characteristic scaling laws. Let's analyze these patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scaling_analysis"
   },
   "outputs": [],
   "source": [
    "def calculate_contact_vs_distance(contact_map, max_distance=None):\n",
    "    \"\"\"Calculate average contact probability vs genomic distance\"\"\"\n",
    "    n = contact_map.shape[0]\n",
    "    if max_distance is None:\n",
    "        max_distance = n // 4\n",
    "    \n",
    "    distances = []\n",
    "    contact_probs = []\n",
    "    \n",
    "    for d in range(1, max_distance):\n",
    "        # Get all pairs at distance d\n",
    "        contacts = []\n",
    "        for i in range(n - d):\n",
    "            contacts.append(contact_map[i, i + d])\n",
    "        \n",
    "        if contacts:\n",
    "            distances.append(d)\n",
    "            contact_probs.append(np.mean(contacts))\n",
    "    \n",
    "    return np.array(distances), np.array(contact_probs)\n",
    "\n",
    "# Calculate scaling\n",
    "distances, contact_probs = calculate_contact_vs_distance(ensemble_contacts, max_distance=200)\n",
    "\n",
    "# Fit power law: P(s) ~ s^(-alpha)\n",
    "# Use log-log fit\n",
    "valid_indices = (contact_probs > 0) & (distances > 5)  # Avoid very short distances\n",
    "valid_distances = distances[valid_indices]\n",
    "valid_probs = contact_probs[valid_indices]\n",
    "\n",
    "log_distances = np.log10(valid_distances)\n",
    "log_probs = np.log10(valid_probs)\n",
    "\n",
    "# Linear fit in log space\n",
    "coeffs = np.polyfit(log_distances, log_probs, 1)\n",
    "alpha = -coeffs[0]  # Scaling exponent\n",
    "intercept = coeffs[1]\n",
    "\n",
    "# Generate fit line\n",
    "fit_distances = np.logspace(np.log10(5), np.log10(200), 50)\n",
    "fit_probs = 10**(intercept) * fit_distances**(-alpha)\n",
    "\n",
    "# Plot scaling analysis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Linear scale\n",
    "ax1.plot(distances, contact_probs, 'bo-', alpha=0.7, markersize=4)\n",
    "ax1.set_xlabel('Genomic Distance (monomers)')\n",
    "ax1.set_ylabel('Contact Probability')\n",
    "ax1.set_title('Contact Probability vs Distance')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Log-log scale\n",
    "ax2.loglog(distances, contact_probs, 'bo', alpha=0.7, markersize=4, label='Data')\n",
    "ax2.loglog(fit_distances, fit_probs, 'r-', linewidth=2, \n",
    "           label=f'Power law fit: α = {alpha:.2f}')\n",
    "ax2.set_xlabel('Genomic Distance (monomers)')\n",
    "ax2.set_ylabel('Contact Probability')\n",
    "ax2.set_title('Scaling Analysis (log-log)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Polymer scaling analysis:\")\n",
    "print(f\"Scaling exponent α = {alpha:.3f}\")\n",
    "print(f\"\")\n",
    "print(f\"Theoretical predictions:\")\n",
    "print(f\"  Ideal chain: α = 1.5\")\n",
    "print(f\"  Self-avoiding walk: α ≈ 1.8\")\n",
    "print(f\"  Compact globule: α ≈ 1.0\")\n",
    "print(f\"  Ring polymer: α ≈ 1.0-1.5\")\n",
    "print(f\"\")\n",
    "print(f\"Your polymer shows {'ideal chain' if 1.4 < alpha < 1.6 else 'self-avoiding' if 1.7 < alpha < 1.9 else 'compact' if alpha < 1.3 else 'unknown'} behavior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "advanced_analysis"
   },
   "source": [
    "## 6. Advanced Contact Map Analysis\n",
    "\n",
    "Let's explore more sophisticated analysis techniques used in Hi-C data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "insulation_analysis"
   },
   "outputs": [],
   "source": [
    "def calculate_insulation_score(contact_map, window_size=20):\n",
    "    \"\"\"Calculate insulation score along the diagonal\"\"\"\n",
    "    n = contact_map.shape[0]\n",
    "    insulation = np.zeros(n)\n",
    "    \n",
    "    for i in range(window_size, n - window_size):\n",
    "        # Calculate mean contact frequency in upstream-downstream windows\n",
    "        upstream_downstream = contact_map[i-window_size:i, i:i+window_size]\n",
    "        insulation[i] = np.mean(upstream_downstream)\n",
    "    \n",
    "    return insulation\n",
    "\n",
    "def calculate_directionality_index(contact_map, window_size=20):\n",
    "    \"\"\"Calculate directionality index (bias in upstream vs downstream contacts)\"\"\"\n",
    "    n = contact_map.shape[0]\n",
    "    directionality = np.zeros(n)\n",
    "    \n",
    "    for i in range(window_size, n - window_size):\n",
    "        # Upstream contacts\n",
    "        upstream = np.sum(contact_map[i-window_size:i, i:i+window_size])\n",
    "        # Downstream contacts  \n",
    "        downstream = np.sum(contact_map[i:i+window_size, i-window_size:i])\n",
    "        \n",
    "        total = upstream + downstream\n",
    "        if total > 0:\n",
    "            directionality[i] = (upstream - downstream) / total\n",
    "    \n",
    "    return directionality\n",
    "\n",
    "# Calculate advanced metrics\n",
    "insulation = calculate_insulation_score(ensemble_contacts, window_size=25)\n",
    "directionality = calculate_directionality_index(ensemble_contacts, window_size=25)\n",
    "\n",
    "# Plot advanced analysis\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "\n",
    "# Contact map with annotations\n",
    "im = axes[0].imshow(ensemble_contacts, cmap='Reds', origin='lower', aspect='auto')\n",
    "axes[0].set_title('Ensemble Contact Map')\n",
    "axes[0].set_xlabel('Monomer index')\n",
    "axes[0].set_ylabel('Monomer index')\n",
    "plt.colorbar(im, ax=axes[0], label='Contact probability')\n",
    "\n",
    "# Insulation score\n",
    "positions = np.arange(len(insulation))\n",
    "axes[1].plot(positions, insulation, 'b-', linewidth=1.5)\n",
    "axes[1].fill_between(positions, insulation, alpha=0.3)\n",
    "axes[1].set_title('Insulation Score (identifies domain boundaries)')\n",
    "axes[1].set_xlabel('Genomic Position')\n",
    "axes[1].set_ylabel('Insulation Score')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Identify potential boundaries (local minima in insulation)\n",
    "from scipy.signal import find_peaks\n",
    "# Find valleys (invert and find peaks)\n",
    "valleys, _ = find_peaks(-insulation[50:-50], height=-np.percentile(insulation[50:-50], 25))\n",
    "valleys += 50  # Adjust for offset\n",
    "\n",
    "for valley in valleys:\n",
    "    axes[1].axvline(valley, color='red', linestyle='--', alpha=0.7)\n",
    "    axes[0].axvline(valley, color='red', linestyle='--', alpha=0.7)\n",
    "    axes[0].axhline(valley, color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Directionality index\n",
    "axes[2].plot(positions, directionality, 'g-', linewidth=1.5)\n",
    "axes[2].axhline(0, color='black', linestyle='-', alpha=0.5)\n",
    "axes[2].fill_between(positions, directionality, alpha=0.3)\n",
    "axes[2].set_title('Directionality Index (identifies contact asymmetry)')\n",
    "axes[2].set_xlabel('Genomic Position')\n",
    "axes[2].set_ylabel('Directionality Index')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Advanced analysis results:\")\n",
    "print(f\"Potential domain boundaries detected: {len(valleys)}\")\n",
    "print(f\"Boundary positions: {valleys}\")\n",
    "print(f\"Average domain size: {np.diff(valleys).mean():.1f} monomers\" if len(valleys) > 1 else \"\")\n",
    "print(f\"Insulation score range: {np.min(insulation[50:-50]):.4f} - {np.max(insulation[50:-50]):.4f}\")\n",
    "print(f\"Directionality range: {np.min(directionality[50:-50]):.3f} - {np.max(directionality[50:-50]):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "compartment_analysis"
   },
   "source": [
    "## 7. Compartment Analysis\n",
    "\n",
    "Large-scale chromatin organization can be analyzed using principal component analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pca_analysis"
   },
   "outputs": [],
   "source": [
    "def calculate_compartments(contact_map, resolution=50):\n",
    "    \"\"\"Calculate A/B compartments using PCA\"\"\"\n",
    "    # Bin the contact map to lower resolution\n",
    "    n = contact_map.shape[0]\n",
    "    n_bins = n // resolution\n",
    "    \n",
    "    binned_map = np.zeros((n_bins, n_bins))\n",
    "    for i in range(n_bins):\n",
    "        for j in range(n_bins):\n",
    "            i_start, i_end = i * resolution, (i + 1) * resolution\n",
    "            j_start, j_end = j * resolution, (j + 1) * resolution\n",
    "            binned_map[i, j] = np.mean(contact_map[i_start:i_end, j_start:j_end])\n",
    "    \n",
    "    # Observed/Expected normalization\n",
    "    oe_map = np.zeros_like(binned_map)\n",
    "    for d in range(n_bins):\n",
    "        if d == 0:\n",
    "            continue\n",
    "        diagonal_values = [binned_map[i, i + d] for i in range(n_bins - d) if binned_map[i, i + d] > 0]\n",
    "        if diagonal_values:\n",
    "            expected = np.mean(diagonal_values)\n",
    "            for i in range(n_bins - d):\n",
    "                if binned_map[i, i + d] > 0:\n",
    "                    oe_map[i, i + d] = binned_map[i, i + d] / expected\n",
    "                    oe_map[i + d, i] = oe_map[i, i + d]\n",
    "    \n",
    "    # PCA on correlation matrix\n",
    "    correlation_matrix = np.corrcoef(oe_map)\n",
    "    # Handle NaN values\n",
    "    correlation_matrix = np.nan_to_num(correlation_matrix)\n",
    "    \n",
    "    # Eigendecomposition\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(correlation_matrix)\n",
    "    \n",
    "    # First PC (largest eigenvalue)\n",
    "    pc1 = eigenvectors[:, -1]  # Last column has largest eigenvalue\n",
    "    \n",
    "    return pc1, oe_map, binned_map\n",
    "\n",
    "# Calculate compartments\n",
    "pc1, oe_map, binned_map = calculate_compartments(ensemble_contacts, resolution=40)\n",
    "\n",
    "# Plot compartment analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Original contact map\n",
    "im1 = axes[0,0].imshow(ensemble_contacts, cmap='Reds', origin='lower')\n",
    "axes[0,0].set_title('Original Contact Map')\n",
    "axes[0,0].set_xlabel('Monomer index')\n",
    "axes[0,0].set_ylabel('Monomer index')\n",
    "plt.colorbar(im1, ax=axes[0,0], shrink=0.7)\n",
    "\n",
    "# Binned contact map\n",
    "im2 = axes[0,1].imshow(binned_map, cmap='Reds', origin='lower')\n",
    "axes[0,1].set_title('Binned Contact Map')\n",
    "axes[0,1].set_xlabel('Bin index')\n",
    "axes[0,1].set_ylabel('Bin index')\n",
    "plt.colorbar(im2, ax=axes[0,1], shrink=0.7)\n",
    "\n",
    "# O/E contact map\n",
    "im3 = axes[1,0].imshow(oe_map, cmap='RdBu_r', origin='lower', vmin=0.5, vmax=1.5)\n",
    "axes[1,0].set_title('Observed/Expected Contact Map')\n",
    "axes[1,0].set_xlabel('Bin index')\n",
    "axes[1,0].set_ylabel('Bin index')\n",
    "plt.colorbar(im3, ax=axes[1,0], shrink=0.7)\n",
    "\n",
    "# PC1 (compartment signal)\n",
    "bin_positions = np.arange(len(pc1))\n",
    "colors = ['red' if x > 0 else 'blue' for x in pc1]\n",
    "axes[1,1].bar(bin_positions, pc1, color=colors, alpha=0.7)\n",
    "axes[1,1].axhline(0, color='black', linestyle='-', alpha=0.8)\n",
    "axes[1,1].set_title('PC1 - A/B Compartments')\n",
    "axes[1,1].set_xlabel('Bin index')\n",
    "axes[1,1].set_ylabel('PC1 value')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add compartment annotation to O/E map\n",
    "for i, val in enumerate(pc1):\n",
    "    color = 'red' if val > 0 else 'blue'\n",
    "    axes[1,0].axhline(i, color=color, alpha=0.3, linewidth=2)\n",
    "    axes[1,0].axvline(i, color=color, alpha=0.3, linewidth=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compartment statistics\n",
    "a_compartment = np.sum(pc1 > 0)\n",
    "b_compartment = np.sum(pc1 < 0)\n",
    "\n",
    "print(f\"Compartment analysis results:\")\n",
    "print(f\"A compartment bins: {a_compartment} ({a_compartment/len(pc1)*100:.1f}%)\")\n",
    "print(f\"B compartment bins: {b_compartment} ({b_compartment/len(pc1)*100:.1f}%)\")\n",
    "print(f\"PC1 range: {np.min(pc1):.3f} to {np.max(pc1):.3f}\")\n",
    "print(f\"\")\n",
    "print(f\"Interpretation:\")\n",
    "print(f\"  Red regions (A compartment): Active, gene-rich regions\")\n",
    "print(f\"  Blue regions (B compartment): Inactive, heterochromatic regions\")\n",
    "print(f\"  PC1 captures the dominant pattern of genome organization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "experimental_comparison"
   },
   "source": [
    "## 8. Comparison with Experimental Data\n",
    "\n",
    "Let's simulate what our contact map might look like as experimental Hi-C data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hic_simulation"
   },
   "outputs": [],
   "source": [
    "def simulate_hic_noise(contact_map, coverage=1000000, noise_level=0.1):\n",
    "    \"\"\"Simulate Hi-C sequencing noise and coverage effects\"\"\"\n",
    "    # Convert probabilities to expected read counts\n",
    "    expected_counts = contact_map * coverage\n",
    "    \n",
    "    # Add Poisson noise (sequencing noise)\n",
    "    noisy_counts = np.random.poisson(expected_counts)\n",
    "    \n",
    "    # Add systematic noise\n",
    "    systematic_noise = np.random.normal(1.0, noise_level, contact_map.shape)\n",
    "    noisy_counts = noisy_counts * systematic_noise\n",
    "    \n",
    "    # Ensure symmetry\n",
    "    noisy_counts = (noisy_counts + noisy_counts.T) / 2\n",
    "    \n",
    "    # Set diagonal to zero (Hi-C removes adjacent ligation products)\n",
    "    np.fill_diagonal(noisy_counts, 0)\n",
    "    \n",
    "    return noisy_counts.astype(int)\n",
    "\n",
    "def normalize_hic_data(counts_matrix):\n",
    "    \"\"\"Apply ICE normalization (iterative correction)\"\"\"\n",
    "    # Simple bias removal (not full ICE implementation)\n",
    "    normalized = counts_matrix.astype(float)\n",
    "    \n",
    "    # Remove bins with very low coverage\n",
    "    bin_sums = np.sum(normalized, axis=1)\n",
    "    valid_bins = bin_sums > np.percentile(bin_sums, 10)\n",
    "    \n",
    "    # Iterative correction (simplified)\n",
    "    for iteration in range(10):\n",
    "        bin_sums = np.sum(normalized, axis=1)\n",
    "        bin_sums[bin_sums == 0] = 1  # Avoid division by zero\n",
    "        correction = np.sqrt(np.mean(bin_sums[valid_bins]) / bin_sums)\n",
    "        \n",
    "        # Apply correction\n",
    "        normalized = normalized * correction[:, np.newaxis]\n",
    "        normalized = normalized * correction[np.newaxis, :]\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "# Simulate Hi-C data\n",
    "hic_counts = simulate_hic_noise(ensemble_contacts, coverage=500000, noise_level=0.15)\n",
    "hic_normalized = normalize_hic_data(hic_counts)\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Theoretical contact map\n",
    "im1 = axes[0,0].imshow(ensemble_contacts, cmap='Reds', origin='lower')\n",
    "axes[0,0].set_title('Theoretical Contact Map\\n(Simulation Truth)')\n",
    "axes[0,0].set_xlabel('Monomer index')\n",
    "axes[0,0].set_ylabel('Monomer index')\n",
    "plt.colorbar(im1, ax=axes[0,0], shrink=0.8)\n",
    "\n",
    "# Raw Hi-C counts\n",
    "im2 = axes[0,1].imshow(hic_counts, cmap='Reds', origin='lower')\n",
    "axes[0,1].set_title('Simulated Hi-C Counts\\n(with noise)')\n",
    "axes[0,1].set_xlabel('Monomer index')\n",
    "axes[0,1].set_ylabel('Monomer index')\n",
    "plt.colorbar(im2, ax=axes[0,1], shrink=0.8)\n",
    "\n",
    "# Normalized Hi-C\n",
    "im3 = axes[0,2].imshow(hic_normalized, cmap='Reds', origin='lower')\n",
    "axes[0,2].set_title('Normalized Hi-C Data\\n(ICE-like correction)')\n",
    "axes[0,2].set_xlabel('Monomer index')\n",
    "axes[0,2].set_ylabel('Monomer index')\n",
    "plt.colorbar(im3, ax=axes[0,2], shrink=0.8)\n",
    "\n",
    "# Log-scale comparisons\n",
    "log_theoretical = np.log10(ensemble_contacts + 1e-6)\n",
    "log_counts = np.log10(hic_counts + 1)\n",
    "log_normalized = np.log10(hic_normalized + 1e-6)\n",
    "\n",
    "axes[1,0].imshow(log_theoretical, cmap='Reds', origin='lower')\n",
    "axes[1,0].set_title('Log-scale Theoretical')\n",
    "axes[1,0].set_xlabel('Monomer index')\n",
    "\n",
    "axes[1,1].imshow(log_counts, cmap='Reds', origin='lower')\n",
    "axes[1,1].set_title('Log-scale Hi-C Counts')\n",
    "axes[1,1].set_xlabel('Monomer index')\n",
    "\n",
    "axes[1,2].imshow(log_normalized, cmap='Reds', origin='lower')\n",
    "axes[1,2].set_title('Log-scale Normalized')\n",
    "axes[1,2].set_xlabel('Monomer index')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare scaling laws\n",
    "distances_theory, probs_theory = calculate_contact_vs_distance(ensemble_contacts)\n",
    "distances_hic, probs_hic = calculate_contact_vs_distance(hic_normalized)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.loglog(distances_theory, probs_theory, 'bo-', alpha=0.7, label='Theoretical', markersize=4)\n",
    "plt.loglog(distances_hic, probs_hic, 'ro-', alpha=0.7, label='Simulated Hi-C', markersize=4)\n",
    "plt.xlabel('Genomic Distance')\n",
    "plt.ylabel('Contact Probability')\n",
    "plt.title('Scaling Comparison: Theory vs Simulated Hi-C')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation\n",
    "flat_theory = ensemble_contacts[np.triu_indices_from(ensemble_contacts, k=1)]\n",
    "flat_hic = hic_normalized[np.triu_indices_from(hic_normalized, k=1)]\n",
    "correlation = np.corrcoef(flat_theory, flat_hic)[0, 1]\n",
    "\n",
    "print(f\"Hi-C simulation results:\")\n",
    "print(f\"Total Hi-C reads: {np.sum(hic_counts):,}\")\n",
    "print(f\"Mean reads per bin: {np.mean(hic_counts):.1f}\")\n",
    "print(f\"Correlation (theory vs Hi-C): {correlation:.3f}\")\n",
    "print(f\"\")\n",
    "print(f\"This demonstrates how polymer simulations can:\")\n",
    "print(f\"  • Predict contact patterns seen in Hi-C experiments\")\n",
    "print(f\"  • Account for experimental noise and biases\")\n",
    "print(f\"  • Validate theoretical models against real data\")\n",
    "print(f\"  • Guide interpretation of genomic contact maps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "## 9. Summary and Applications\n",
    "\n",
    "🎉 **Congratulations!** You've mastered contact map analysis with polychrom!\n",
    "\n",
    "### What You've Learned:\n",
    "\n",
    "✅ **Contact map fundamentals**: Converting 3D coordinates to 2D contact matrices\n",
    "\n",
    "✅ **Ensemble averaging**: Proper statistical analysis of polymer trajectories\n",
    "\n",
    "✅ **Scaling laws**: Understanding polymer physics through contact probability vs distance\n",
    "\n",
    "✅ **Advanced analysis**: Insulation scores, directionality index, and domain detection\n",
    "\n",
    "✅ **Compartment analysis**: PCA-based identification of large-scale organization\n",
    "\n",
    "✅ **Experimental comparison**: Simulating Hi-C noise and normalization procedures\n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "🔬 **Polymer physics**: Contact probability follows power laws characteristic of polymer conformations\n",
    "\n",
    "📊 **Data analysis**: Multiple analysis approaches reveal different organizational levels\n",
    "\n",
    "🧬 **Biology connection**: Simulations can predict and explain experimental Hi-C patterns\n",
    "\n",
    "⚖️ **Model validation**: Comparing theory with experiment validates mechanistic models\n",
    "\n",
    "### Real-World Applications:\n",
    "\n",
    "🏥 **Disease research**: Compare healthy vs disease chromatin organization\n",
    "\n",
    "🧬 **Drug discovery**: Predict how compounds affect 3D genome structure\n",
    "\n",
    "🔬 **Basic research**: Test hypotheses about chromatin organization mechanisms\n",
    "\n",
    "📈 **Data interpretation**: Understand what Hi-C experiments actually measure\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "🔧 **Tool development**: \n",
    "- Build automated contact map analysis pipelines\n",
    "- Develop statistical tests for comparing contact maps\n",
    "- Create visualization tools for 3D genome organization\n",
    "\n",
    "📊 **Advanced analysis**:\n",
    "- Multi-resolution contact map analysis\n",
    "- Time-resolved contact map dynamics\n",
    "- Machine learning approaches to pattern recognition\n",
    "\n",
    "🧬 **Biological applications**:\n",
    "- Study specific genomic loci (gene clusters, chromatin domains)\n",
    "- Model disease-associated structural variants\n",
    "- Investigate cell-type-specific chromatin organization\n",
    "\n",
    "### Learn More:\n",
    "\n",
    "- 📖 [Polychrom Documentation](https://polychrom.readthedocs.io/)\n",
    "- 🔄 [Loop Extrusion Tutorial](https://colab.research.google.com/github/darinddv/polychrom/blob/master/tutorials/02_loop_extrusion_simulation.ipynb)\n",
    "- 🧮 [Basic Polymer Tutorial](https://colab.research.google.com/github/darinddv/polychrom/blob/master/tutorials/01_basic_polymer_simulation.ipynb)\n",
    "- 💻 [GitHub Repository](https://github.com/darinddv/polychrom)\n",
    "- 📚 [Hi-C Analysis Tools](https://github.com/mirnylab/cooltools)\n",
    "\n",
    "### Research Opportunities:\n",
    "\n",
    "The field of 3D genome organization is rapidly evolving. Your skills in contact map analysis position you to contribute to:\n",
    "\n",
    "- **Computational biology**: Developing new analysis methods\n",
    "- **Biophysics**: Understanding the physics of chromosome organization\n",
    "- **Medicine**: Linking 3D genome structure to disease\n",
    "- **Biotechnology**: Engineering chromatin organization for synthetic biology\n",
    "\n",
    "---\n",
    "\n",
    "**Ready for the next challenge?** Explore how these contact map analysis techniques apply to real biological questions in chromatin organization and gene regulation!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
